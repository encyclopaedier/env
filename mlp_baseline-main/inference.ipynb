{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import multiprocessing\n",
    "from model import mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "['/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_results/mlp_baseline/mlp_0/best.pth', '/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_results/mlp_baseline/mlp_1/best.pth', '/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_results/mlp_baseline/mlp_2/best.pth', '/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_results/mlp_baseline/mlp_3/best.pth', '/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_results/mlp_baseline/mlp_4/best.pth']\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data/local_data/shared/102/intern_data_yzhou/zy4_parquet'\n",
    "mean_std_path = '/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/data_processed/mean_std_all.pkl'\n",
    "feas = pd.read_pickle('/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/feas353.pkl')\n",
    "feas = [i for i in feas if 'x_' in i]\n",
    "feas = [i for i in feas if 'x_1663' not in i]\n",
    "fea_nums = len(feas) \n",
    "print(fea_nums)\n",
    "\n",
    "onnx_save_path = f'/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_models/mlp_baseline' \n",
    "path = '/mnt/beegfs/strategy_intern/zzdai_intern/for_wpxu/nn_results/mlp_baseline'\n",
    "md_list = [f'mlp_{i}' for i in range(5)]\n",
    "model_list = [os.path.join(path, i) for i in md_list]\n",
    "model_path_list = [os.path.join(i, 'best.pth') for i in model_list]\n",
    "print(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(onnx_save_path):\n",
    "    os.makedirs(onnx_save_path)\n",
    "shutil.copyfile(mean_std_path, os.path.join(onnx_save_path, 'mean_std_all.pkl'))\n",
    "pd.to_pickle(feas, os.path.join(onnx_save_path, 'feas.pkl'))\n",
    "\n",
    "\n",
    "for i, md_path in enumerate(model_path_list):\n",
    "    shutil.copyfile(md_path, os.path.join(onnx_save_path, md_list[i].split('/')[-1]+'.pth'))\n",
    "    onnx_path = os.path.join(onnx_save_path, md_list[i].split('/')[-1]+'.onnx')\n",
    "    model_i = mlp(len(feas))\n",
    "    model_i.eval() # 若存在batchnorm、dropout层则一定要eval()!!!!再export\n",
    "    ckpt = torch.load(md_path, map_location=torch.device('cpu'))\n",
    "    model_i.load_state_dict(ckpt, strict=True)\n",
    "    \n",
    "    dummy_input = torch.randn((2**14, fea_nums))\n",
    "    torch.onnx.export(model_i, dummy_input, onnx_path, input_names=['input_0'], output_names=['output_0'],\n",
    "    dynamic_axes={'input_0':{0: 'batch'}, 'output_0':{0: 'batch'}}) #, opset_version = 11)\n",
    "    onnx_model = onnx.load(onnx_path) # 加载onnx\n",
    "    onnx.checker.check_model(onnx_model) \n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    }
   ],
   "source": [
    "fea_path = os.path.join(onnx_save_path, 'feas.pkl')\n",
    "mean_std_path = os.path.join(onnx_save_path, 'mean_std_all.pkl')\n",
    "start_date = '20200601'\n",
    "end_date = '20210331'\n",
    "y_name = 'm1_ts_y_60twap_2n1open_Wgted_fullmarket_ex'\n",
    "feas = pd.read_pickle(fea_path)\n",
    "print(len(feas))\n",
    "mean_std_df = pd.read_pickle(mean_std_path)\n",
    "means = mean_std_df.loc[:, 'mean'].astype(np.float32)\n",
    "stds = mean_std_df.loc[:, 'std']\n",
    "stds = stds.apply(lambda x: max(1e-10, x)).astype(np.float32)\n",
    "\n",
    "def get_pred_df_mp2(model_path, feas, means, stds, date_start, date_end, stacking_type):\n",
    "    nn_models = []\n",
    "    for i in os.listdir(onnx_save_path):\n",
    "        if '.onnx' not in i:\n",
    "            continue\n",
    "        nn_models.append(onnxruntime.InferenceSession(os.path.join(model_path, i), providers=['CPUExecutionProvider']))\n",
    "    files = f'{data_path}/{date_start}.parquet'\n",
    "    dataset = pq.ParquetDataset(files, use_legacy_dataset=False)\n",
    "    df_pred = dataset.read(columns=['date', 'TimeStamp', 'ticker']).to_pandas()\n",
    "    df_pred['model_pred'] = 0.0\n",
    "    _df_pred = df_pred.copy()\n",
    "    \n",
    "    test_x = dataset.read(columns=feas).to_pandas()\n",
    "    test_x.replace([-np.inf, np.inf], np.nan, inplace=True)\n",
    "    # test_x.fillna(method='ffill', inplace=True)\n",
    "    test_x = (test_x - means.loc[feas])/stds.loc[feas]\n",
    "    test_x.fillna(0, inplace=True)\n",
    "    # test_x.loc[:, 'x_1663'] = 0\n",
    "    \n",
    "    test_x = test_x.astype(np.float32)\n",
    "    input = test_x.values\n",
    "    for nn_model in nn_models:\n",
    "        ort_output = nn_model.run(['output_0'], {'input_0': input})[0] \n",
    "        _df_pred['model_pred'] = ort_output.reshape(-1)\n",
    "        if stacking_type == 'rank':\n",
    "            _df_pred['model_pred'] = _df_pred.groupby(['TimeStamp'])['model_pred'].rank(axis=0, pct=True)\n",
    "        df_pred['model_pred'] += _df_pred['model_pred']/len(nn_models)\n",
    "    print(date_start, 'finished')\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200629 finished\n",
      "20200624 finished20200617\n",
      " finished\n",
      "20200605 finished\n",
      "20200602 finished\n",
      "20200702 finished\n",
      "20200616 finished\n",
      "20200611 20200615 finished20200622 \n",
      "finished\n",
      "finished\n",
      "20200618 finished\n",
      "2020060820200619 finished\n",
      " finished\n",
      "20200604 finished\n",
      "20200612 finished\n",
      "20200603 finished\n",
      "20200601 \n",
      "finished20200610 finished\n",
      "20200706 20200630finished \n",
      "finished\n",
      "20200701 finished20200703\n",
      " finished\n",
      "20200707 finished\n",
      "2020071020200709  finishedfinished\n",
      "\n",
      "20200623 finished\n",
      "20200609 finished\n",
      "20200708 finished\n",
      "20200715 finished\n",
      "20200714 finished\n",
      "20200716 finished\n",
      "20200713 finished\n",
      "20200723 finished\n",
      "20200722 finished\n",
      "20200826 20200717finished \n",
      "finished\n",
      "2020081320200814 finished finished\n",
      "20200810\n",
      " finished\n",
      "20200820 finished20200728 \n",
      "finished\n",
      "20200807 20200720finished\n",
      " finished\n",
      "20200803 finished\n",
      "20200827 finished\n",
      "20200727 finished\n",
      "20200724 finished\n",
      "20200730 \n",
      "finished20200824 finished\n",
      "20200821 finished\n",
      "20200729 finished\n",
      "20200825 finished\n",
      "20200721 finished\n",
      "20200806 finished\n",
      "20200819 finished\n",
      "20200817 finished\n",
      "20200812 finished\n",
      "20200731 finished\n",
      "20200818 finished\n",
      "20200804 finished20200805\n",
      " finished\n",
      "20200811 finished\n",
      "20200828 finished\n",
      "20200831 finished\n",
      "20200911 finished\n",
      "20200901 finished\n",
      "20200902 finished20200930\n",
      " finished\n",
      "2020101220200928  finished\n",
      "finished\n",
      "20200903 finished\n",
      "202009292020090420200907 finished\n",
      " finished\n",
      " finished\n",
      "20201019 finished\n",
      "20200917 finished20201016 \n",
      "finished\n",
      "20200916 finished\n",
      "20200909 finished\n",
      "20200914 finished\n",
      "2020092420201009  finishedfinished\n",
      "\n",
      "20200923 finished\n",
      "20200908 finished\n",
      "20200925 finished\n",
      "20201015 finished\n",
      "20201013 finished\n",
      "20200910 finished\n",
      "20201014 finished\n",
      "20200922 finished\n",
      "20201020 finished\n",
      "20200921 finished\n",
      "20200915 finished\n",
      "20200918 finished20201021\n",
      " finished\n",
      "20201022 finished\n",
      "20201026 finished\n",
      "20201110 finished\n",
      "20201118 finished\n",
      "20201102 finished\n",
      "20201103 finished\n",
      "20201127 finished\n",
      "20201023 finished\n",
      "20201105 20201112 finished\n",
      "20201204finished\n",
      " finished\n",
      "20201028 finished\n",
      "20201111 finished\n",
      "20201124 finished\n",
      "20201104 finished\n",
      "20201119 finished20201106 \n",
      "finished\n",
      "20201027 finished\n",
      "20201126 finished\n",
      "20201123 finished\n",
      "20201030 finished\n",
      "20201116 finished\n",
      "20201113 finished\n",
      "20201109 finished\n",
      "20201201 finished\n",
      "20201117 finished\n",
      "20201125 finished\n",
      "20201202 finished\n",
      "20201120 finished\n",
      "20201029 finished\n",
      "20201203 finished\n",
      "20201207 finished\n",
      "20201130 finished\n",
      "20201208 finished\n",
      "20210112 finished\n",
      "20201223 finished\n",
      "20210114 finished\n",
      "20201214 finished\n",
      "20201231 finished20210115\n",
      " finished\n",
      "20201209 finished\n",
      "20201215 finished\n",
      "20201222 finished\n",
      "2021010620210113  finished\n",
      "finished\n",
      "20210119 finished\n",
      "20201210 finished\n",
      "20210108 20201224finished\n",
      " finished\n",
      "20210105 finished\n",
      "20201230 finished\n",
      "20201218 finished\n",
      "20201225 finished\n",
      "20201217 finished\n",
      "20210111 finished\n",
      "20210118 finished\n",
      "20201216 finished\n",
      "20201211 finished\n",
      "20201221 finished\n",
      "20201229 finished\n",
      "20201228 finished\n",
      "20210104 finished\n",
      "20210120 finished\n",
      "20210107 finished\n",
      "20210121 finished\n",
      "20210122 finished\n",
      "20210208 finished\n",
      "20210209 finished\n",
      "20210203 finished\n",
      "20210129 finished\n",
      "20210126 finished\n",
      "20210310 finished\n",
      "20210304 finished20210204\n",
      "20210127 finished\n",
      " finished\n",
      "20210218 20210305finished \n",
      "finished\n",
      "20210128 finished20210308\n",
      " finished\n",
      "20210311 20210201finished\n",
      " finished\n",
      "20210302 finished20210219\n",
      " finished\n",
      "20210125 finished\n",
      "20210205 finished\n",
      "20210210 finished\n",
      "20210309 finished\n",
      "20210301 finished\n",
      "20210222 finished\n",
      "20210226 finished\n",
      "20210202 finished\n",
      "20210223 finished\n",
      "20210225 finished\n",
      "20210315 finished\n",
      "20210303 20210312finished\n",
      " finished\n",
      "20210224 finished\n",
      "20210317 finished\n",
      "20210318 finished\n",
      "20210319 finished\n",
      "20210316 finished\n",
      "20210322 finished\n",
      "20210323 finished\n",
      "20210331 finished\n",
      "20210324 finished\n",
      "20210325 finished\n",
      "20210330 finished\n",
      "20210326 finished\n",
      "20210329 finished\n"
     ]
    }
   ],
   "source": [
    "file_list = sorted(os.listdir(data_path))\n",
    "date_all = [i.split('.')[0] for i in file_list]\n",
    "date_list = [date for date in date_all if date>=start_date and date<=end_date]\n",
    "\n",
    "mul_dfs = []\n",
    "df_pred_all = []\n",
    "pool = multiprocessing.Pool(32)\n",
    "for i, dt in enumerate(date_list):\n",
    "    mul_dfs.append(pool.apply_async(get_pred_df_mp2, (onnx_save_path, feas, means, stds, dt, dt, 'rank')))\n",
    "for item in mul_dfs:\n",
    "    df_pred_all.append(item.get())\n",
    "pool.close()\n",
    "\n",
    "df_pred_all = pd.concat(df_pred_all)\n",
    "df_pred_all = df_pred_all.sort_values(by=['date','TimeStamp','ticker'], )\n",
    "pd.to_pickle(df_pred_all, os.path.join(onnx_save_path, 'model_pred.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rtn': 0.45248598,\n",
       " 'sharpe': 7.818074910237697,\n",
       " 'rtn_mtt': 0.4437583,\n",
       " 'sharpe_mtt': 8.953303192129178,\n",
       " 'turnover': 0.7296788713910266,\n",
       " 'rtn_fee': 0.22047657424182757,\n",
       " 'exp_size_mean': -0.9351935264285018,\n",
       " 'exp_size_min': -1.5661436005472904,\n",
       " 'exp_size_max': 0.2935770728711605,\n",
       " 'exp_bp_mean': -0.27353997251075635,\n",
       " 'exp_bp_min': -0.8705440397548537,\n",
       " 'exp_bp_max': 0.45323319260747674,\n",
       " 'exp_rv_mean': 0.03812554507776968,\n",
       " 'exp_rv_min': -0.8473830994345523,\n",
       " 'exp_rv_max': 0.8700684433532738,\n",
       " 'kcb_ratio_mean': 0.06650735278792719,\n",
       " 'kcb_ratio_max': 0.16065573770491803,\n",
       " 'cyb_ratio_mean': 0.2683294522776527,\n",
       " 'cyb_ratio_max': 0.652}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import get_eval_result\n",
    "from PqiDataSdk import *\n",
    "\n",
    "# 获取评价用收益\n",
    "# 起始日期\n",
    "date_s = start_date\n",
    "# 结束日期\n",
    "date_e = end_date\n",
    "ds = PqiDataSdk(user=\"wpxu\", size=1, pool_type=\"mp\", str_map=False)\n",
    "dates = ds.get_trade_dates(start_date=date_s, end_date=date_e)\n",
    "data_path = '/data/local_data/shared/102/intern_data_yzhou/zy4_parquet'\n",
    "files = [f'{data_path}/{i}.parquet' for i in dates] #所有数据文件\n",
    "y_name = 'm1_ts_y_60twap_2n1open_Wgted_fullmarket_ex' #指定1天后收益y值\n",
    "zt_filter = ('m1_ts_z_tag_up_limit','=',0.0)\n",
    "dt_filter = ('m1_ts_z_tag_down_limit','=',0.0)\n",
    "yna_filter = (y_name,'!=',np.nan)\n",
    "filters = [zt_filter,dt_filter,yna_filter]\n",
    "dataset = pq.ParquetDataset(files, use_legacy_dataset=False, filters=filters)\n",
    "cols = ['date', 'TimeStamp','ticker', y_name]\n",
    "df_eval = dataset.read(columns=cols).to_pandas()\n",
    "# 开始评价模型表现，建议分20 21年\n",
    "param_dict = {\n",
    "    'crss_ratio_thr': 0.03,\n",
    "    'max_trade_time': 1,\n",
    "    'index_code':'000905',\n",
    "    'start_date':'20200601',\n",
    "    'end_date':'20210331',\n",
    "    'y_name': y_name\n",
    "}\n",
    "get_eval_result(param_dict, df_eval, df_pred_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rtn': 0.13077165,\n",
       " 'sharpe': 7.290189315939747,\n",
       " 'rtn_mtt': 0.12716727,\n",
       " 'sharpe_mtt': 8.380594501906193,\n",
       " 'turnover': 0.7209812873266889,\n",
       " 'rtn_fee': 0.06444189759009485,\n",
       " 'exp_size_mean': -0.934032994799822,\n",
       " 'exp_size_min': -1.5661436005472904,\n",
       " 'exp_size_max': 0.2935770728711605,\n",
       " 'exp_bp_mean': -0.21991784764812175,\n",
       " 'exp_bp_min': -0.8705440397548537,\n",
       " 'exp_bp_max': 0.37908718357451615,\n",
       " 'exp_rv_mean': 0.034422427591791746,\n",
       " 'exp_rv_min': -0.5148980499238308,\n",
       " 'exp_rv_max': 0.628956876913992,\n",
       " 'kcb_ratio_mean': 0.07662383630371776,\n",
       " 'kcb_ratio_max': 0.15544041450777202,\n",
       " 'cyb_ratio_mean': 0.23251235902586645,\n",
       " 'cyb_ratio_max': 0.42091836734693877}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {\n",
    "    'crss_ratio_thr': 0.03,\n",
    "    'max_trade_time': 1,\n",
    "    'index_code':'000905',\n",
    "    'start_date':'20210101',\n",
    "    'end_date':'20210331',\n",
    "    'y_name': y_name\n",
    "}\n",
    "get_eval_result(param_dict, df_eval, df_pred_all)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "568415f8034d4245baef1815eee350d86d872e0622f7175a8825f29df393c837"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
